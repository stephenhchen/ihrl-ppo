{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "import tensorboard as tb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_value_name(summary):\n",
    "    value_name = summary.summary.value[0].tag\n",
    "    return value_name\n",
    "\n",
    "def extract_env_step(summary):\n",
    "    step = summary.step\n",
    "    return step\n",
    "\n",
    "def extract_scalar_value(summary):\n",
    "    val = summary.summary.value[0].simple_value\n",
    "    return val\n",
    "\n",
    "def extract_tb_results(run_dir: str,\n",
    "                       run_list: List,\n",
    "                       stat_name1: str,\n",
    "                       stat_name2: str) -> \\\n",
    "                           Dict[str, Tuple[List, Dict[str, List]]]:\n",
    "\n",
    "    runs = {}\n",
    "    for i in range(len(run_list)):    # extract for every seed\n",
    "        run = run_list[i]\n",
    "        full_run_dir = run_dir / run\n",
    "        assert len(os.listdir(full_run_dir)) == 1\n",
    "        full_run_path = full_run_dir / os.listdir(full_run_dir)[0]\n",
    "\n",
    "        steps = []\n",
    "        stat1, stat2 = [], []   # reward, success\n",
    "        for summary in summary_iterator(str(full_run_path)):\n",
    "            if len(summary.summary.value) == 0:\n",
    "                # has no summary value\n",
    "                continue\n",
    "            \n",
    "            value_name = extract_value_name(summary)\n",
    "            \n",
    "            # extract stat such as rollout/ep_rew_mean\n",
    "            if value_name == stat_name1:\n",
    "                val = extract_scalar_value(summary)\n",
    "                stat1.append(val)\n",
    "                step = extract_env_step(summary)\n",
    "                steps.append(step)\n",
    "                # print(stat_name, val)\n",
    "\n",
    "            if value_name == stat_name2:\n",
    "                val = extract_scalar_value(summary)\n",
    "                stat2.append(val)\n",
    "\n",
    "        # print('\\n')\n",
    "        runs[run] = (steps, stat1, stat2)\n",
    "\n",
    "    return runs\n",
    "\n",
    "def trunc_runs(runs): \n",
    "    # after gathering runs, truncate each to the smallest number of steps across seeds\n",
    "    # most of the time, it should be the same, but depends on if I decided to stop early\n",
    "    min_steps = get_min_steps_across_seeds(runs)\n",
    "    new_runs = {}\n",
    "    for run_name, (steps, stat1, stat2) in runs.items():\n",
    "        steps, stat1, stat2 = steps[:min_steps], stat1[:min_steps], stat2[:min_steps]\n",
    "        new_runs[run_name] = (steps, stat1, stat2)\n",
    "    return new_runs\n",
    "\n",
    "def adjust_steps_stat(steps, stat1, stat2):\n",
    "    # start graph from zero\n",
    "    if isinstance(steps, np.ndarray) and isinstance(stat1, np.ndarray) and isinstance(stat2, np.ndarray):\n",
    "        steps, stat1, stat2 = list(steps), list(stat1), list(stat2)\n",
    "    return [0]+steps, [stat1[0]] + stat1, [stat2[0]] + stat2\n",
    "\n",
    "def get_min_steps_across_seeds(runs):\n",
    "    min_epi = np.inf\n",
    "    for run_name in runs:\n",
    "        steps, _,  _ = runs[run_name]\n",
    "        print(f\"num steps for {run_name}: {len(steps)}\")\n",
    "        min_epi = np.minimum(min_epi, len(steps)).astype(int)\n",
    "    return min_epi\n",
    "\n",
    "# compute mean / std across seeds\n",
    "def get_means_std_over_seeds(runs):\n",
    "\n",
    "    all_stat1, all_stat2 = [], []\n",
    "    for run_name in runs:\n",
    "        _, stat1, stat2 = runs[run_name]\n",
    "        all_stat1.append(stat1)\n",
    "        all_stat2.append(stat2)\n",
    "    \n",
    "    all_stat1, all_stat2 = np.array(all_stat1), np.array(all_stat2)\n",
    "    \n",
    "    mean1_per_step = np.mean(all_stat1, axis=0).tolist()\n",
    "    std1_per_step = np.std(all_stat1, axis=0).tolist()\n",
    "    \n",
    "    mean2_per_step = np.mean(all_stat2, axis=0).tolist()\n",
    "    std2_per_step = np.std(all_stat2, axis=0).tolist()\n",
    "    \n",
    "    results = ((np.array(mean1_per_step), np.array(std1_per_step)),\n",
    "               (np.array(mean2_per_step), np.array(std2_per_step)))\n",
    "     \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = {\n",
    "    \"mini_behavior\": {\n",
    "        \"installing_printer\": [\"install_printer\"],\n",
    "        \"thawing\": [\"thaw_fish\", \"thaw_date\", \"thaw_olive\", \"thaw_any_two\", \"thaw_all\"],\n",
    "        \"cleaning_car\": [\"soak_rag\", \"clean_car\", \"clean_rag\"]\n",
    "    }, \n",
    "    \"igibson\": {\n",
    "        \"igibson\": [\"fruit\", \"fruit_sink\", \"knife\", \"knife_sink\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "PARENT_LOG_DIR = Path('baselines/ppo/logs/neurips/tb/')\n",
    "\n",
    "stat_name1 = 'eval/mean_reward'\n",
    "stat_name2 = 'eval/success_rate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for env_suite in [\"mini_behavior\"]:\n",
    "# for env_suite in [\"mini_behavior\", \"igibson\"]:\n",
    "    print(env_suite)\n",
    "\n",
    "    for task in all_tasks[env_suite]:\n",
    "        print(\"processing task:\", task)\n",
    "        if task == \"thawing\" or task == \"installing_printer\": continue\n",
    "        \n",
    "        print(task)\n",
    "        task_names = all_tasks[env_suite][task]\n",
    "        RUN_DIR =  PARENT_LOG_DIR / env_suite / task\n",
    "\n",
    "        for specific_task in task_names:\n",
    "            print(specific_task)\n",
    "            \n",
    "            SPEC_RUN_DIR = RUN_DIR / specific_task\n",
    "            RUN_LIST = os.listdir(SPEC_RUN_DIR)      # each dir in this list is a run per seed\n",
    "            print(f'RUNS FOUND in {SPEC_RUN_DIR}:') \n",
    "            print(RUN_LIST)\n",
    "            runs = extract_tb_results(SPEC_RUN_DIR, RUN_LIST, stat_name1, stat_name2)      # dict containing each run as a key, value is a tuple (step, metric_val)\n",
    "            print(f\"Runs found for {specific_task}:\", runs.keys())\n",
    "            \n",
    "            runs = {run_name: adjust_steps_stat(steps, stat1, stat2)\n",
    "                    for run_name, (steps, stat1, stat2) in runs.items()}\n",
    "\n",
    "            # steps should be the same across all runs, take the first\n",
    "            # steps, _, _= truncate_runs[list(truncate_runs.keys())[0]]\n",
    "            # truncate_runs = trunc_runs(runs)\n",
    "            \n",
    "            truncate_runs = runs\n",
    "            # steps, _, _= truncate_runs[list(runs.keys())[0]] \n",
    "            (rew_means, rew_stds), (suc_means, suc_stds) = get_means_std_over_seeds(truncate_runs)\n",
    "            \n",
    "            # create output csv\n",
    "            for run in runs:\n",
    "                print(f\"processing run:{run}\")\n",
    "                if run == 'run-seed1-20240519-21:07_1': continue\n",
    "\n",
    "                steps, rew, suc = runs[run]\n",
    "                output = pd.DataFrame(pd.Series(steps, name='timestep')).set_index(\"timestep\")\n",
    "                rew = pd.Series(rew, index=steps, name='average_reward')\n",
    "                output = output.join(rew)\n",
    "                suc = pd.Series(suc, index=steps, name=\"average_success\")\n",
    "                output = output.join(suc)\n",
    "                \n",
    "                seed_name = run.split(\"-\")[1]\n",
    "                assert seed_name[:-1] == \"seed\"\n",
    "                seed = seed_name[-1]\n",
    "                fname = f\"trial{seed}.csv\"\n",
    "                output_dir = Path(\"results\") / env_suite / task / specific_task\n",
    "                output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                output.to_csv(output_dir / fname)\n",
    "\n",
    "        print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEANING CAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "env_suite = 'mini_behavior'\n",
    "task = 'cleaning_car'\n",
    "specific_task = 'clean_car'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract\n",
    "runs = extract_tb_results(RUN_LIST, stat_name1, stat_name2)      # dict containing each run as a key, value is a tuple (step, metric_val)\n",
    "print(\"Runs found:\", runs.keys())\n",
    "print(\"Number of (steps, rew, success) to plot:\", len(runs['run-seed0-20240410-18:47_1'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {run_name: adjust_steps_stat(steps, stat1, stat2)\n",
    "        for run_name, (steps, stat1, stat2) in runs.items()}\n",
    "trunc_runs = truncate_runs(runs)\n",
    "\n",
    "# steps should be the same across all runs, take the first\n",
    "steps, _, _= trunc_runs[list(trunc_runs.keys())[0]] \n",
    "(rew_means, rew_stds), (suc_means, suc_stds) = get_means_std_over_seeds(trunc_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(steps, rew_means)\n",
    "plt.fill_between(steps, rew_means-rew_stds, rew_means+rew_stds, color='b', alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(steps, suc_means)\n",
    "plt.fill_between(steps, suc_means-suc_stds, suc_means+suc_stds, color='b', alpha=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAN RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTALL PRINTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THAW FISH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGIBSON KNIFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGIBSON FRUIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOAK RAG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ihrl-csd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
